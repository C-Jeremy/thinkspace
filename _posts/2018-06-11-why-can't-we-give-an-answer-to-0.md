---
title: Why Can't We Give An Answer to 0/0?
author: Jeremy
category: Mathematics
permalink: /dividing-by-zero
date: 2018-06-11
---

*Student*: What’s the answer to *0/0*?

*Teacher*: It’s undefined.

*Student*: Then why can’t *we* define it?

*Teacher*: Because that’s just how division works.

The exchange above is one that happens often when students start learning division. It’s a simple question, arising since we can divide by any *other* number, so why not this one? Unfortunately, the answers given to this question don’t attack the consequences of defining *0/0*, but explains it as something given by authority.


I often like to remind students of a very important lesson when they start wondering about the definitions and restrictions that come up. **We get to make up the definitions used in mathematics.** We aren't *forced* to use a certain definition for a concept if we don't want to! Mathematics is about defining concepts and building from them, but we get to choose those starting points.

One specific example where things can get controversial is when we start considering an expression like 0/0. In this case, what is the answer?

As the teacher said above, we leave this expression as undefined. In other words, we say that the statement just doesn't make sense, and we move on. However, if the definitions are up to us, why can't we define these to take on certain values? What's the harm in that?

This is a good question, and answering it will give us insight into the notion of divisibility. What does it mean for a number to "divide" another? If you ponder this question, you will find that we can divide *b* by *a* if we can write *b=ac*, where *c* is another element. Note that I'm using the word "element" here because we don't necessarily have to be working with integers, though that is the setting which is most familiar.

There's another property that we would like, even though you may have implicity assumed this. It's that *if* we can indeed write *b=ac*, the element *c* is unique. If we take the example of 20/5, we know that the only way to write this is *20=(5)(4)*. Four is the unique number that we get when performing the division.

So what about zero? If we want to find an answer to *0/0*, we need to find a number such that *0=0a*. What kind of numbers fit the bill? One works, since *(0)(1)=0*, but two works as well. Actually, you will quite quickly realize that *all* numbers work. That's because you're multiplying by zero, which "collapses" every single number to zero when you multiply them together.

Now we're faced with a bit of a dilemma. Which number should we choose to be the answer? Remember, we have all the freedom in the world to create our own definition of things! Let's say we choose *0/0=5*. Then, what happens if we consider *(0/0)(0/0)*? On the one hand, we know that each term in the parentheses is 5, so we should get a result of 25. However, if we do the multiplication in our usual way, we also get that *(0/0)(0/0)=(0/0)=5*. As such, we would conclude that *5=25*. This is clearly not a very good number system, since any time I owe you twenty-five dollars, I'll only give you back five. We *know* that those two numbers should be different, so it's a bit of a concern when we manage to say that they are equal to each other.

---

The lesson we learn from this is that, while we *do* have the freedom to define concepts however we wish, we also want to be consistent. If we can transform five into twenty-five, it turns out that we can make basically any number we want equal to five. This is not a system in which the usual arithmetic rules apply. That's not inherently bad, but we need to ask ourselves if the tradeoffs are worth it. Is it a good idea to have 0/0 being equal to *any* number we want as soon as we say it's equal to a specific number, or is it better to leave it as undefined? As a community, mathematicians have obviously chosen the path of not defining terms like 0/0, and it's precisely for this reason. Our common sense goes out the window once we start allowing these kinds of expressions.

In fact, you may have seen "pseudo-proofs" that *1=2*, and these proofs rely on the fact that they are sneaking in a "divide by zero" operation at some point. Of course, these "proofs" won't mention that, but that is the trick that is being played.

While it is easy to define these expressions to take on a certain value, there's a *reason* why this isn't done. We aren't just lazy and don't want to divide by zero. It's that zero is a fundamentally different sort of number, and dividing by it doesn't give us a unique answer.

However, it is *much* more fascinating to delve into why we don't divide by zero, rather than simply forcing you to memorize this in class, don't you think?
